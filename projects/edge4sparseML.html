<p>
    Advancements in intelligent technical systems (ITS) are transforming industrial production, particularly in image processing,
    by leveraging AI and machine learning (ML) techniques such as Deep Neural Networks (DNN) and Convolutional Neural Networks (CNN).
    However, the performance of these methods often depends on high-performance computing (HPC) in the cloud, which poses challenges
    for real-time applications requiring low latency and data locality, especially in rail-processing systems.
</p>
<p>
    To address this, the project aims to develop a modular methodology for efficiently running AI/ML algorithms on resource-constrained hardware.
    It explores automated design-space optimization within a HW/AI co-design framework, ensuring optimal AI-hardware integration for industrial
    applications with strict latency requirements. Beyond the traditional linear model-to-inference process, the approach also considers the
    reciprocal impact of hardware choices on initial model development.</p>
</p>